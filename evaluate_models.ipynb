{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import load_dataset\n",
    "from sentence_transformers import SentenceTransformer, util\n",
    "import time\n",
    "from elasticsearch import Elasticsearch, helpers\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'name': 'e22daf50a33f',\n",
       " 'cluster_name': 'docker-cluster',\n",
       " 'cluster_uuid': 'VVaP-BPiSyKO_yho-aX1Hg',\n",
       " 'version': {'number': '8.7.0',\n",
       "  'build_flavor': 'default',\n",
       "  'build_type': 'docker',\n",
       "  'build_hash': '09520b59b6bc1057340b55750186466ea715e30e',\n",
       "  'build_date': '2023-03-27T16:31:09.816451435Z',\n",
       "  'build_snapshot': False,\n",
       "  'lucene_version': '9.5.0',\n",
       "  'minimum_wire_compatibility_version': '7.17.0',\n",
       "  'minimum_index_compatibility_version': '7.0.0'},\n",
       " 'tagline': 'You Know, for Search'}"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "es = Elasticsearch(\"http://localhost:9200\")\n",
    "es.info().body"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "eval_dataset = load_dataset(\"nlplabtdtu/xquad_benchmark\",split='train')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['question', 'contexts'],\n",
       "    num_rows: 1190\n",
       "})"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "eval_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5950\n",
      "240\n"
     ]
    }
   ],
   "source": [
    "unique_context = []\n",
    "for row in eval_dataset:\n",
    "    # print(row)\n",
    "    for context in row['contexts']:\n",
    "        unique_context.append(context)\n",
    "print(len(unique_context))\n",
    "unique_context = list(set(unique_context))\n",
    "print(len(unique_context))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "distil_sbert_model = SentenceTransformer('nlplabtdtu/distil-sbert-base-uncased')\n",
    "sbert_70M_model = SentenceTransformer('nlplabtdtu/sbert-70M-cased')\n",
    "sbert_30M_model = SentenceTransformer('nlplabtdtu/sbert-30M-uncased')\n",
    "miniLM_model = SentenceTransformer('nlplabtdtu/sbert-all-MiniLM-L6-v2')\n",
    "gte_small_model = SentenceTransformer('nlplabtdtu/gte-small')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_5588/520888510.py:34: DeprecationWarning: Passing transport options in the API method is deprecated. Use 'Elasticsearch.options()' instead.\n",
      "  es.indices.create(index='eval_data_index', body=es_index, ignore=[400])\n",
      "/tmp/ipykernel_5588/520888510.py:34: DeprecationWarning: The 'body' parameter is deprecated and will be removed in a future version. Instead use individual parameters.\n",
      "  es.indices.create(index='eval_data_index', body=es_index, ignore=[400])\n"
     ]
    }
   ],
   "source": [
    "if not es.indices.exists(index=\"eval_data_index\"):\n",
    "    try:\n",
    "      es_index = {\n",
    "        \"mappings\": {\n",
    "          \"properties\": {\n",
    "\n",
    "            \"body\": {\n",
    "              \"type\": \"text\"\n",
    "            },\n",
    "            \"body_distil_vector\": {\n",
    "              \"type\": \"dense_vector\",\n",
    "              \"dims\": 768\n",
    "            },\n",
    "            \"body_70M_vector\": {\n",
    "              \"type\": \"dense_vector\",\n",
    "              \"dims\": 768\n",
    "            },\n",
    "            \"body_30M_vector\": {\n",
    "              \"type\": \"dense_vector\",\n",
    "              \"dims\": 512\n",
    "            },\n",
    "            \"body_mini_vector\": {\n",
    "              \"type\": \"dense_vector\",\n",
    "              \"dims\": 768\n",
    "            },\n",
    "            \"body_gte_vector\": {\n",
    "              \"type\": \"dense_vector\",\n",
    "              \"dims\": 384\n",
    "            },\n",
    "          }\n",
    "        }\n",
    "      }\n",
    "\n",
    "      es.indices.create(index='eval_data_index', body=es_index, ignore=[400])\n",
    "      bulk_data = []\n",
    "      for i in range(len(unique_context)):\n",
    "        distil_embedding = distil_sbert_model.encode(unique_context[i], show_progress_bar=False)\n",
    "        sbert_70M_embedding = sbert_70M_model.encode(unique_context[i], show_progress_bar=False)\n",
    "        sbert_30M_embedding = sbert_30M_model.encode(unique_context[i], show_progress_bar=False)\n",
    "        miniLM_embedding = miniLM_model.encode(unique_context[i], show_progress_bar=False)\n",
    "        gte_small_embedding = gte_small_model.encode(unique_context[i], show_progress_bar=False)\n",
    "        bulk_data.append({\n",
    "                \"_index\": 'eval_data_index',\n",
    "                \"_source\": {\n",
    "                    \"body\": unique_context[i],\n",
    "                    \"body_distil_vector\": distil_embedding,\n",
    "                    \"body_70M_vector\": sbert_70M_embedding,\n",
    "                    \"body_30M_vector\": sbert_30M_embedding,\n",
    "                    \"body_mini_vector\": miniLM_embedding,\n",
    "                    \"body_gte_vector\": gte_small_embedding\n",
    "                }\n",
    "            })\n",
    "      # print(bulk_data[0])\n",
    "\n",
    "      helpers.bulk(es, bulk_data)\n",
    "\n",
    "    except:\n",
    "        print(\"During index an exception occured. Continue\\n\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ObjectApiResponse({'_shards': {'total': 2, 'successful': 1, 'failed': 0}})"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "es.indices.refresh(index=\"eval_data_index\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "distil_embedding_questions = []\n",
    "sbert_70M_embedding_questions = []\n",
    "sbert_30M_embedding_questions = []\n",
    "miniLM_embedding_questions = []\n",
    "gte_small_embedding_questions = []\n",
    "for row in eval_dataset:\n",
    "    distil_embedding_questions.append(distil_sbert_model.encode(row['question'], show_progress_bar=False))\n",
    "    sbert_70M_embedding_questions.append(sbert_70M_model.encode(row['question'], show_progress_bar=False))\n",
    "    sbert_30M_embedding_questions.append(sbert_30M_model.encode(row['question'], show_progress_bar=False))\n",
    "    miniLM_embedding_questions.append(miniLM_model.encode(row['question'], show_progress_bar=False))\n",
    "    gte_small_embedding_questions.append(gte_small_model.encode(row['question'], show_progress_bar=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_5588/2499344312.py:6: DeprecationWarning: The 'body' parameter is deprecated and will be removed in a future version. Instead use individual parameters.\n",
      "  bm25 = es.search(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total time: 21.417574167251587\n",
      "Accuracy: 0.9840336134453781\n"
     ]
    }
   ],
   "source": [
    "#BM25\n",
    "start_time = time.time()\n",
    "count_true = 0\n",
    "for row in eval_dataset:\n",
    "    inp_question = row['question']\n",
    "    bm25 = es.search(\n",
    "        index=\"eval_data_index\", \n",
    "        body={\"query\": \n",
    "            {\"match\": {\"body\": inp_question }}\n",
    "        },\n",
    "        size=10\n",
    "    )\n",
    "    for hit in bm25['hits']['hits']:\n",
    "        if hit['_source']['body'] == row['contexts'][-1]:\n",
    "            count_true += 1\n",
    "            break\n",
    "end_time = time.time()\n",
    "print(\"Total time:\", end_time - start_time)\n",
    "print(\"Accuracy:\", count_true/len(eval_dataset))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_5588/3465885436.py:7: DeprecationWarning: The 'body' parameter is deprecated and will be removed in a future version. Instead use individual parameters.\n",
      "  sem_search = es.search(index=\"eval_data_index\", body=\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total time: 14.167500257492065\n",
      "Accuracy: 0.8025210084033614\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "start_time = time.time()\n",
    "count_true = 0\n",
    "for i in range(len(eval_dataset)):\n",
    "    # inp_question = row[i]['question']\n",
    "    gte_small_embedding_question = gte_small_embedding_questions[i]\n",
    "    sem_search = es.search(index=\"eval_data_index\", body=\n",
    "                       {\n",
    "                            \"query\": {\n",
    "                                \"script_score\": {\n",
    "                                    \"query\" : {\n",
    "                                        \"match_all\": {},\n",
    "                                    },\n",
    "                                    \"script\": {\n",
    "                                        \"source\": \"cosineSimilarity(params.query_vector, 'body_gte_vector') + 1.0\", \n",
    "                                        \"params\": {\n",
    "                                            \"query_vector\": gte_small_embedding_question\n",
    "                                        }\n",
    "                                    }\n",
    "                                }\n",
    "                            }\n",
    "                        },\n",
    "                        size=1\n",
    "    )\n",
    "    for hit in sem_search['hits']['hits']:\n",
    "        if hit['_source']['body'] == eval_dataset[i]['contexts'][-1]:\n",
    "            count_true += 1\n",
    "            break\n",
    "end_time = time.time()\n",
    "print(\"Total time:\", end_time - start_time)\n",
    "print(\"Accuracy:\", count_true/len(eval_dataset))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_5588/1240057399.py:6: DeprecationWarning: The 'body' parameter is deprecated and will be removed in a future version. Instead use individual parameters.\n",
      "  bm25 = es.search(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total time: 31.20016384124756\n",
      "Accuracy: 0.838655462184874\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "start_time = time.time()\n",
    "count_true = 0\n",
    "for i in range(len(eval_dataset)):\n",
    "    inp_question = eval_dataset[i]['question']\n",
    "    bm25 = es.search(\n",
    "        index=\"eval_data_index\", \n",
    "        body={\"query\": \n",
    "            {\"match\": {\"body\": inp_question }}\n",
    "        },\n",
    "        size=10\n",
    "    )\n",
    "\n",
    "    encoded_contexts = [hit['_source']['body_gte_vector'] for hit in bm25['hits']['hits']]\n",
    "    encoded_contexts = torch.tensor(encoded_contexts)\n",
    "    contexts = [hit['_source']['body'] for hit in bm25['hits']['hits']]\n",
    "    result = util.semantic_search(torch.tensor(gte_small_embedding_questions[i]), encoded_contexts, top_k=1)\n",
    "    # print(result)\n",
    "    for hit in result[0]:\n",
    "        if contexts[int(hit['corpus_id'])] == eval_dataset[i]['contexts'][-1]:\n",
    "            count_true += 1\n",
    "            break\n",
    "    # if contexts[int(result[0][0]['corpus_id'])] == eval_dataset[i]['contexts'][-1]:\n",
    "    #     count_true += 1\n",
    "    # else:\n",
    "    #     print(f\"predict: {contexts[int(result[0][0]['corpus_id'])]}\")\n",
    "    #     print(contexts)\n",
    "    #     print(inp_question)\n",
    "    #     break\n",
    "end_time = time.time()\n",
    "print(\"Total time:\", end_time - start_time)\n",
    "print(\"Accuracy:\", count_true/len(eval_dataset))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "elastic",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
